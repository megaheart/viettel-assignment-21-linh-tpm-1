{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType\n",
    "\n",
    "action_schema = StructType().add(\"student_code\", \"integer\")\\\n",
    "    .add(\"activity\", \"string\")\\\n",
    "    .add(\"numberOfFile\", \"integer\")\\\n",
    "    .add(\"timestamp\", \"string\")\n",
    "\n",
    "sv_de_schema = StructType().add(\"student_code\", \"integer\")\\\n",
    "    .add(\"fullname\", \"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save danh_sach_sv_de to hdfs with path: /raw_zone/danh_sach_sv_de.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|student_code|            fullname|\n",
      "+------------+--------------------+\n",
      "|           1|          Mai Đức An|\n",
      "|           2|      Nguyễn Mai Anh|\n",
      "|           3|   Ngô Ngọc Tuấn Anh|\n",
      "|           4|      Trần Trung Anh|\n",
      "|           5|       Trần Ngọc Bảo|\n",
      "|           6|  Nguyễn Vũ Hòa Bình|\n",
      "|           7|    Nguyễn Thành Đạt|\n",
      "|           8|        Đỗ Thành Đạt|\n",
      "|           9|    Nguyễn Khoa Đoàn|\n",
      "|          10|    Nguyễn Quốc Dũng|\n",
      "|          11|     Đường Minh Quân|\n",
      "|          12|   Dương Quang Giang|\n",
      "|          13|    Nguyễn Minh Hiếu|\n",
      "|          14|        Ngô Phi Hùng|\n",
      "|          15|Nguyễn Đình Thiên...|\n",
      "|          16|        Đỗ Doãn Khắc|\n",
      "|          17|      Châu Minh Khải|\n",
      "|          18|      Phạm Đình Khôi|\n",
      "|          19|        Lê Bảo Khánh|\n",
      "|          20|        Lê Minh Phúc|\n",
      "+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\", \"false\").schema(sv_de_schema)\\\n",
    "    .load(\"./data/danh_sach_sv_de.csv\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"csv\").option(\"header\", \"false\").mode(\"overwrite\")\\\n",
    "    .save(\"hdfs://namenode:9000/raw_zone/danh_sach_sv_de\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data in hdfs danh_sach_sv_de và /raw_zone/fact/activity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|student_code|            fullname|\n",
      "+------------+--------------------+\n",
      "|           1|          Mai Đức An|\n",
      "|           2|      Nguyễn Mai Anh|\n",
      "|           3|   Ngô Ngọc Tuấn Anh|\n",
      "|           4|      Trần Trung Anh|\n",
      "|           5|       Trần Ngọc Bảo|\n",
      "|           6|  Nguyễn Vũ Hòa Bình|\n",
      "|           7|    Nguyễn Thành Đạt|\n",
      "|           8|        Đỗ Thành Đạt|\n",
      "|           9|    Nguyễn Khoa Đoàn|\n",
      "|          10|    Nguyễn Quốc Dũng|\n",
      "|          11|     Đường Minh Quân|\n",
      "|          12|   Dương Quang Giang|\n",
      "|          13|    Nguyễn Minh Hiếu|\n",
      "|          14|        Ngô Phi Hùng|\n",
      "|          15|Nguyễn Đình Thiên...|\n",
      "|          16|        Đỗ Doãn Khắc|\n",
      "|          17|      Châu Minh Khải|\n",
      "|          18|      Phạm Đình Khôi|\n",
      "|          19|        Lê Bảo Khánh|\n",
      "|          20|        Lê Minh Phúc|\n",
      "|          21| Trần Phúc Mạnh Linh|\n",
      "|          22|       Huỳnh Tấn Lộc|\n",
      "|          23|Nguyễn Địch Nhật ...|\n",
      "|          24|     Nguyễn Hoài Nam|\n",
      "|          25|    Đào Thanh Nguyên|\n",
      "|          26|     Nguyễn Duy Hưng|\n",
      "|          27|Nguyễn Thị Thùy T...|\n",
      "|          28|Lương Thị Mai Phương|\n",
      "|          29|    Nguyễn Minh Quân|\n",
      "|          30|     Phùng Huy Quang|\n",
      "|          31|         Tạ Đức Tiến|\n",
      "|          32|     Đinh Việt Thành|\n",
      "|          33|     Nguyễn Bá Thiêm|\n",
      "|          34|       Huỳnh Minh Tú|\n",
      "|          35|    Nguyễn Minh Tuấn|\n",
      "|          36|        Vũ Khắc Long|\n",
      "|          37|          Đào Anh Vũ|\n",
      "|          38|           Vũ Hữu Sỹ|\n",
      "|          39|       Huỳnh Đoan Hồ|\n",
      "+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sv_de_df = spark.read.format(\"csv\").option(\"header\", \"false\").schema(sv_de_schema)\\\n",
    "    .load(\"hdfs://namenode:9000/raw_zone/danh_sach_sv_de\")\n",
    "sv_de_df.show(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+------------+---------+\n",
      "|student_code|activity|numberOfFile|timestamp|\n",
      "+------------+--------+------------+---------+\n",
      "|           4|   write|           7|6/10/2024|\n",
      "|          33|    read|           5|6/12/2024|\n",
      "|          33| execute|           1|6/13/2024|\n",
      "|           6|   write|           6|6/15/2024|\n",
      "|          24| execute|           8|6/12/2024|\n",
      "|          22|   write|           2|6/12/2024|\n",
      "|          31|   write|           9|6/13/2024|\n",
      "|           8|   write|           4|6/13/2024|\n",
      "|          21|    read|           5|6/12/2024|\n",
      "|          26| execute|           2|6/10/2024|\n",
      "|          24|    read|          10|6/12/2024|\n",
      "|          10|    read|           6|6/15/2024|\n",
      "|          20|   write|           7|6/14/2024|\n",
      "|          14| execute|           7|6/11/2024|\n",
      "|           5| execute|           1|6/10/2024|\n",
      "|           3|    read|           9|6/13/2024|\n",
      "|          11|   write|           7|6/11/2024|\n",
      "|           7|    read|           1|6/15/2024|\n",
      "|          22|   write|           9|6/14/2024|\n",
      "|           4| execute|           8|6/13/2024|\n",
      "+------------+--------+------------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "action_df = spark.read.parquet(\"hdfs://namenode:9000/raw_zone/fact/activity\",\n",
    "                               schema=action_schema)\n",
    "action_df.show()\n",
    "print(action_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data from /raw_zone/danh_sach_sv_de.csv and save to data/Tran_Phuc_Manh_Linh.csv\n",
    "\n",
    "Đưa ra tổng số file được tương tác hàng ngày theo mỗi loại activity\n",
    "mà sinh viên đó thực hiện. Lưu ra 1 file ouput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_format, to_date\n",
    "\n",
    "output_df = action_df\\\n",
    "    .withColumn(\"timestamp\", date_format(to_date(action_df[\"timestamp\"], \"M/d/yyyy\"), \"yyyyMMdd\"))\\\n",
    "    .groupBy([\"student_code\", \"activity\", \"timestamp\"])\\\n",
    "    .sum(\"numberOfFile\")\\\n",
    "    .join(sv_de_df, \"student_code\", \"left\")\\\n",
    "    .orderBy(\"timestamp\", \"student_code\", \"activity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/Tran_Phuc_Manh_Linh.csv\", \"w\", encoding='utf-8') as f:\n",
    "    f.write(\"date,student_code,student_name,activity,totalFile\\n\")\n",
    "    for row in output_df.collect():\n",
    "        f.write(f\"{row.timestamp},{row.student_code},{row.fullname},{row.activity},{row['sum(numberOfFile)']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu file bằng DataFrame API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.withColumnRenamed(\"sum(numberOfFile)\", \"totalFile\")\\\n",
    "    .withColumnRenamed(\"timestamp\", \"date\")\\\n",
    "    .withColumnRenamed(\"fullname\", \"student_name\")\\\n",
    "    .select(\"date\", \"student_code\", \"student_name\", \"activity\", \"totalFile\")\n",
    "\n",
    "output_df.write.format(\"csv\").option(\"header\", \"true\").mode(\"overwrite\")\\\n",
    "    .save(\"./data/Tran_Phuc_Manh_Linh\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
